Model: "functional_63"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_22 (InputLayer)        [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d_299 (Conv2D)          (None, 28, 28, 32)        320       
_________________________________________________________________
batch_normalization_267 (Bat (None, 28, 28, 32)        128       
_________________________________________________________________
conv2d_300 (Conv2D)          (None, 28, 28, 32)        9248      
_________________________________________________________________
batch_normalization_268 (Bat (None, 28, 28, 32)        128       
_________________________________________________________________
max_pooling2d_40 (MaxPooling (None, 14, 14, 32)        0         
_________________________________________________________________
conv2d_301 (Conv2D)          (None, 14, 14, 64)        18496     
_________________________________________________________________
batch_normalization_269 (Bat (None, 14, 14, 64)        256       
_________________________________________________________________
conv2d_302 (Conv2D)          (None, 14, 14, 64)        36928     
_________________________________________________________________
batch_normalization_270 (Bat (None, 14, 14, 64)        256       
_________________________________________________________________
max_pooling2d_41 (MaxPooling (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_303 (Conv2D)          (None, 7, 7, 128)         73856     
_________________________________________________________________
batch_normalization_271 (Bat (None, 7, 7, 128)         512       
_________________________________________________________________
conv2d_304 (Conv2D)          (None, 7, 7, 128)         147584    
_________________________________________________________________
batch_normalization_272 (Bat (None, 7, 7, 128)         512       
_________________________________________________________________
conv2d_305 (Conv2D)          (None, 7, 7, 256)         295168    
_________________________________________________________________
batch_normalization_273 (Bat (None, 7, 7, 256)         1024      
_________________________________________________________________
conv2d_306 (Conv2D)          (None, 7, 7, 256)         590080    
_________________________________________________________________
batch_normalization_274 (Bat (None, 7, 7, 256)         1024      
_________________________________________________________________
conv2d_307 (Conv2D)          (None, 7, 7, 128)         295040    
_________________________________________________________________
batch_normalization_275 (Bat (None, 7, 7, 128)         512       
_________________________________________________________________
conv2d_308 (Conv2D)          (None, 7, 7, 128)         147584    
_________________________________________________________________
batch_normalization_276 (Bat (None, 7, 7, 128)         512       
_________________________________________________________________
conv2d_309 (Conv2D)          (None, 7, 7, 64)          73792     
_________________________________________________________________
batch_normalization_277 (Bat (None, 7, 7, 64)          256       
_________________________________________________________________
conv2d_310 (Conv2D)          (None, 7, 7, 64)          36928     
_________________________________________________________________
batch_normalization_278 (Bat (None, 7, 7, 64)          256       
_________________________________________________________________
up_sampling2d_38 (UpSampling (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_311 (Conv2D)          (None, 14, 14, 32)        18464     
_________________________________________________________________
batch_normalization_279 (Bat (None, 14, 14, 32)        128       
_________________________________________________________________
conv2d_312 (Conv2D)          (None, 14, 14, 32)        9248      
_________________________________________________________________
batch_normalization_280 (Bat (None, 14, 14, 32)        128       
_________________________________________________________________
up_sampling2d_39 (UpSampling (None, 28, 28, 32)        0         
_________________________________________________________________
conv2d_313 (Conv2D)          (None, 28, 28, 1)         289       
=================================================================
Total params: 1,758,657
Trainable params: 1,755,841
Non-trainable params: 2,816
_______________________________________


Epoch 1/100
  2/329 [..............................] - ETA: 58s - loss: 0.2741WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0601s vs `on_train_batch_end` time: 0.2953s). Check your callbacks.
329/329 [==============================] - 30s 92ms/step - loss: 0.0654 - val_loss: 0.0876
Epoch 2/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0211 - val_loss: 0.0149
Epoch 3/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0123 - val_loss: 0.0100
Epoch 4/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0086 - val_loss: 0.0078
Epoch 5/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0068 - val_loss: 0.0063
Epoch 6/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0057 - val_loss: 0.0054
Epoch 7/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0049 - val_loss: 0.0046
Epoch 8/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0043 - val_loss: 0.0045
Epoch 9/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0039 - val_loss: 0.0037
Epoch 10/100
329/329 [==============================] - 30s 90ms/step - loss: 0.0035 - val_loss: 0.0061
Epoch 11/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0039 - val_loss: 0.0034
Epoch 12/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0032 - val_loss: 0.0041
Epoch 13/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0029 - val_loss: 0.0029
Epoch 14/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0028 - val_loss: 0.0029
Epoch 15/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0026 - val_loss: 0.0033
Epoch 16/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0026 - val_loss: 0.0024
Epoch 17/100
329/329 [==============================] - 30s 90ms/step - loss: 0.0024 - val_loss: 0.0026
Epoch 18/100
329/329 [==============================] - 30s 90ms/step - loss: 0.0023 - val_loss: 0.0036
Epoch 19/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0027 - val_loss: 0.0024
Epoch 20/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0022 - val_loss: 0.0023
Epoch 21/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0022 - val_loss: 0.0021
Epoch 22/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0020 - val_loss: 0.0023
Epoch 23/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0020 - val_loss: 0.0022
Epoch 24/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0019 - val_loss: 0.0020
Epoch 25/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0019 - val_loss: 0.0020
Epoch 26/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0018 - val_loss: 0.0025
Epoch 27/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0018 - val_loss: 0.0020
Epoch 28/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0017 - val_loss: 0.0017
Epoch 29/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0017 - val_loss: 0.0019
Epoch 30/100
329/329 [==============================] - 30s 90ms/step - loss: 0.0017 - val_loss: 0.0018
Epoch 31/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0017 - val_loss: 0.0018
Epoch 32/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0016 - val_loss: 0.0017
Epoch 33/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0016 - val_loss: 0.0021
Epoch 34/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0015 - val_loss: 0.0019
Epoch 35/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0016 - val_loss: 0.0017
Epoch 36/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0015 - val_loss: 0.0019
Epoch 37/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0015 - val_loss: 0.0017
Epoch 38/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0014 - val_loss: 0.0016
Epoch 39/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0014 - val_loss: 0.0016
Epoch 40/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0014 - val_loss: 0.0016
Epoch 41/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0014 - val_loss: 0.0016
Epoch 42/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0014 - val_loss: 0.0015
Epoch 43/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0013 - val_loss: 0.0016
Epoch 44/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0015 - val_loss: 0.0015
Epoch 45/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0013 - val_loss: 0.0014
Epoch 46/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0013 - val_loss: 0.0015
Epoch 47/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0013 - val_loss: 0.0023
Epoch 48/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0013 - val_loss: 0.0018
Epoch 49/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0012 - val_loss: 0.0014
Epoch 50/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0012 - val_loss: 0.0015
Epoch 51/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0012 - val_loss: 0.0015
Epoch 52/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0012 - val_loss: 0.0015
Epoch 53/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0012 - val_loss: 0.0014
Epoch 54/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0012 - val_loss: 0.0019
Epoch 55/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0012 - val_loss: 0.0015
Epoch 56/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0011 - val_loss: 0.0015
Epoch 57/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0012 - val_loss: 0.0015
Epoch 58/100
329/329 [==============================] - 30s 93ms/step - loss: 0.0013 - val_loss: 0.0014
Epoch 59/100
329/329 [==============================] - 30s 93ms/step - loss: 0.0011 - val_loss: 0.0013
Epoch 60/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0011 - val_loss: 0.0014
Epoch 61/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0011 - val_loss: 0.0014
Epoch 62/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0011 - val_loss: 0.0013
Epoch 63/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0011 - val_loss: 0.0013
Epoch 64/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0011 - val_loss: 0.0013
Epoch 65/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0011 - val_loss: 0.0014
Epoch 66/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0011 - val_loss: 0.0012
Epoch 67/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0010 - val_loss: 0.0013
Epoch 68/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0010 - val_loss: 0.0012
Epoch 69/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0010 - val_loss: 0.0012
Epoch 70/100
329/329 [==============================] - 30s 92ms/step - loss: 9.9809e-04 - val_loss: 0.0013
Epoch 71/100
329/329 [==============================] - 30s 91ms/step - loss: 0.0010 - val_loss: 0.0012
Epoch 72/100
329/329 [==============================] - 30s 92ms/step - loss: 9.9010e-04 - val_loss: 0.0012
Epoch 73/100
329/329 [==============================] - 30s 91ms/step - loss: 9.7706e-04 - val_loss: 0.0012
Epoch 74/100
329/329 [==============================] - 30s 92ms/step - loss: 9.7296e-04 - val_loss: 0.0012
Epoch 75/100
329/329 [==============================] - 30s 92ms/step - loss: 9.6151e-04 - val_loss: 0.0012
Epoch 76/100
329/329 [==============================] - 30s 92ms/step - loss: 9.5294e-04 - val_loss: 0.0011
Epoch 77/100
329/329 [==============================] - 30s 91ms/step - loss: 9.4253e-04 - val_loss: 0.0012
Epoch 78/100
329/329 [==============================] - 30s 91ms/step - loss: 9.4094e-04 - val_loss: 0.0014
Epoch 79/100
329/329 [==============================] - 30s 92ms/step - loss: 0.0010 - val_loss: 0.0011
Epoch 80/100
329/329 [==============================] - 30s 92ms/step - loss: 9.3737e-04 - val_loss: 0.0011
Epoch 81/100
329/329 [==============================] - 30s 91ms/step - loss: 9.2087e-04 - val_loss: 0.0013
Epoch 82/100
329/329 [==============================] - 30s 91ms/step - loss: 9.0838e-04 - val_loss: 0.0013
Epoch 83/100
329/329 [==============================] - 30s 92ms/step - loss: 8.9935e-04 - val_loss: 0.0011
Epoch 84/100
329/329 [==============================] - 30s 91ms/step - loss: 9.1402e-04 - val_loss: 0.0012
Epoch 85/100
329/329 [==============================] - 30s 91ms/step - loss: 8.8464e-04 - val_loss: 0.0011
Epoch 86/100
329/329 [==============================] - 30s 91ms/step - loss: 8.8317e-04 - val_loss: 0.0013
Epoch 87/100
329/329 [==============================] - 30s 91ms/step - loss: 8.7928e-04 - val_loss: 0.0016
Epoch 88/100
329/329 [==============================] - 30s 92ms/step - loss: 8.6371e-04 - val_loss: 0.0010
Epoch 89/100
329/329 [==============================] - 30s 91ms/step - loss: 8.5292e-04 - val_loss: 0.0012
Epoch 90/100
329/329 [==============================] - 30s 91ms/step - loss: 8.5073e-04 - val_loss: 0.0011
Epoch 91/100
329/329 [==============================] - 30s 91ms/step - loss: 8.4751e-04 - val_loss: 0.0011
Epoch 92/100
329/329 [==============================] - 30s 91ms/step - loss: 8.4358e-04 - val_loss: 0.0011
Epoch 93/100
329/329 [==============================] - 30s 91ms/step - loss: 8.2915e-04 - val_loss: 0.0012
Epoch 94/100
329/329 [==============================] - 30s 91ms/step - loss: 8.3669e-04 - val_loss: 0.0011
Epoch 95/100
329/329 [==============================] - 30s 92ms/step - loss: 8.3816e-04 - val_loss: 0.0010
Epoch 96/100
329/329 [==============================] - 30s 91ms/step - loss: 8.1223e-04 - val_loss: 0.0011
Epoch 97/100
329/329 [==============================] - 30s 91ms/step - loss: 8.0015e-04 - val_loss: 0.0010
Epoch 98/100
329/329 [==============================] - 30s 91ms/step - loss: 7.9622e-04 - val_loss: 0.0010
Epoch 99/100
329/329 [==============================] - 30s 91ms/step - loss: 8.0565e-04 - val_loss: 0.0010
Epoch 100/100
329/329 [==============================] - 30s 92ms/step - loss: 7.9114e-04 - val_loss: 0.0011
